{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from catboost import CatBoostRanker, Pool\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "df  = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank           0\n",
       "query_id       0\n",
       "feature_0      0\n",
       "feature_1      0\n",
       "feature_2      0\n",
       "              ..\n",
       "feature_139    0\n",
       "feature_140    0\n",
       "feature_141    0\n",
       "feature_142    0\n",
       "feature_143    0\n",
       "Length: 146, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "\n",
    "gss = GroupShuffleSplit(test_size=.20, n_splits=1, random_state=42).split(df, groups=df['query_id'])\n",
    "\n",
    "X_train_inds, X_test_inds = next(gss)\n",
    "\n",
    "train_data= df.iloc[X_train_inds]\n",
    "test_data= df.iloc[X_test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "\n",
    "X_train = train_data.drop(['rank', 'query_id'], axis=1).values\n",
    "y_train = train_data['rank'].values\n",
    "queries_train = train_data['query_id'].values\n",
    "\n",
    "X_test = test_data.drop(['rank', 'query_id'], axis=1).values\n",
    "y_test = test_data['rank'].values\n",
    "queries_test = test_data['query_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 97647), (1, 60601), (2, 25863), (4, 1473), (3, 3405)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relevance labels statistics\n",
    "\n",
    "from collections import Counter\n",
    "Counter(y_train).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to [0,1]\n",
    "\n",
    "max_relevance = np.max(y_train)\n",
    "y_train = y_train / max_relevance\n",
    "y_test = y_test / max_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reation of CatBoost pools\n",
    "\n",
    "train = Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    group_id=queries_train\n",
    ")\n",
    "\n",
    "test = Pool(\n",
    "    data=X_test,\n",
    "    label=y_test,\n",
    "    group_id=queries_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set params\n",
    "\n",
    "params = {\n",
    "    'iterations': 3000,\n",
    "    'custom_metric': ['NDCG:top=5', 'PFound:top=5', 'AverageGain:top=5'],\n",
    "    'verbose': False,\n",
    "    'random_seed': 0,\n",
    "    'thread_count': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create func for fitting\n",
    "\n",
    "def fit_model(loss_function, additional_params=None, train_pool=train, test_pool=test):\n",
    "    parameters = deepcopy(params)\n",
    "    parameters['loss_function'] = loss_function\n",
    "    parameters['train_dir'] = loss_function\n",
    "\n",
    "    if additional_params is not None:\n",
    "        parameters.update(additional_params)\n",
    "\n",
    "    model = CatBoostRanker(**parameters)\n",
    "    model.fit(train_pool, eval_set=test_pool, plot=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3ab4f9a5e74ee0a71f7b0d1b298762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit model\n",
    "\n",
    "model = fit_model('QueryRMSE', params, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PFound:top=5': 0.6975775578613285,\n",
       " 'NDCG:top=5;type=Base': 0.5790497505705205,\n",
       " 'QueryRMSE': 0.17765738143770826,\n",
       " 'AverageGain:top=5': 0.3385416666666665}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_['validation']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
